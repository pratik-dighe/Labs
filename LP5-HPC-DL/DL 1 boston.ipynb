{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c063421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab04801",
   "metadata": {},
   "outputs": [],
   "source": [
    "BostonTrain = pd.read_csv(\"boston_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154a6646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     crim    zn  indus  chas    nox     rm    age     dis  rad  tax  \\\n",
       "0   3  0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242   \n",
       "1   6  0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222   \n",
       "2   8  0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311   \n",
       "3   9  0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311   \n",
       "4  10  0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311   \n",
       "\n",
       "   ptratio   black  lstat  \n",
       "0     17.8  392.83   4.03  \n",
       "1     18.7  394.12   5.21  \n",
       "2     15.2  396.90  19.15  \n",
       "3     15.2  386.63  29.93  \n",
       "4     15.2  386.71  17.10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BostonTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c0a49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173 entries, 0 to 172\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   ID       173 non-null    int64  \n",
      " 1   crim     173 non-null    float64\n",
      " 2   zn       173 non-null    float64\n",
      " 3   indus    173 non-null    float64\n",
      " 4   chas     173 non-null    int64  \n",
      " 5   nox      173 non-null    float64\n",
      " 6   rm       173 non-null    float64\n",
      " 7   age      173 non-null    float64\n",
      " 8   dis      173 non-null    float64\n",
      " 9   rad      173 non-null    int64  \n",
      " 10  tax      173 non-null    int64  \n",
      " 11  ptratio  173 non-null    float64\n",
      " 12  black    173 non-null    float64\n",
      " 13  lstat    173 non-null    float64\n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 19.1 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>258.404624</td>\n",
       "      <td>4.100862</td>\n",
       "      <td>12.661850</td>\n",
       "      <td>10.835145</td>\n",
       "      <td>0.086705</td>\n",
       "      <td>0.549981</td>\n",
       "      <td>6.321237</td>\n",
       "      <td>69.245665</td>\n",
       "      <td>3.958865</td>\n",
       "      <td>9.387283</td>\n",
       "      <td>406.231214</td>\n",
       "      <td>18.469942</td>\n",
       "      <td>351.299711</td>\n",
       "      <td>12.917977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>143.289788</td>\n",
       "      <td>10.607761</td>\n",
       "      <td>24.536277</td>\n",
       "      <td>6.596488</td>\n",
       "      <td>0.282219</td>\n",
       "      <td>0.117826</td>\n",
       "      <td>0.700621</td>\n",
       "      <td>28.248244</td>\n",
       "      <td>2.324131</td>\n",
       "      <td>8.662621</td>\n",
       "      <td>164.480626</td>\n",
       "      <td>2.196196</td>\n",
       "      <td>99.781464</td>\n",
       "      <td>7.293408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.013810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>4.138000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.178100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.082210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>5.895000</td>\n",
       "      <td>42.800000</td>\n",
       "      <td>2.010700</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>371.720000</td>\n",
       "      <td>6.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>268.000000</td>\n",
       "      <td>0.251990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.223000</td>\n",
       "      <td>79.200000</td>\n",
       "      <td>3.421100</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>390.070000</td>\n",
       "      <td>12.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>381.000000</td>\n",
       "      <td>3.673670</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.674000</td>\n",
       "      <td>94.600000</td>\n",
       "      <td>5.400700</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.060000</td>\n",
       "      <td>17.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>505.000000</td>\n",
       "      <td>88.976200</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>34.370000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID        crim          zn       indus        chas         nox  \\\n",
       "count  173.000000  173.000000  173.000000  173.000000  173.000000  173.000000   \n",
       "mean   258.404624    4.100862   12.661850   10.835145    0.086705    0.549981   \n",
       "std    143.289788   10.607761   24.536277    6.596488    0.282219    0.117826   \n",
       "min      3.000000    0.013810    0.000000    0.460000    0.000000    0.392000   \n",
       "25%    136.000000    0.082210    0.000000    5.320000    0.000000    0.447000   \n",
       "50%    268.000000    0.251990    0.000000    8.560000    0.000000    0.538000   \n",
       "75%    381.000000    3.673670   20.000000   18.100000    0.000000    0.624000   \n",
       "max    505.000000   88.976200   95.000000   27.740000    1.000000    0.871000   \n",
       "\n",
       "               rm         age         dis         rad         tax     ptratio  \\\n",
       "count  173.000000  173.000000  173.000000  173.000000  173.000000  173.000000   \n",
       "mean     6.321237   69.245665    3.958865    9.387283  406.231214   18.469942   \n",
       "std      0.700621   28.248244    2.324131    8.662621  164.480626    2.196196   \n",
       "min      4.138000    2.900000    1.178100    1.000000  187.000000   12.600000   \n",
       "25%      5.895000   42.800000    2.010700    4.000000  279.000000   17.000000   \n",
       "50%      6.223000   79.200000    3.421100    5.000000  330.000000   19.100000   \n",
       "75%      6.674000   94.600000    5.400700   24.000000  666.000000   20.200000   \n",
       "max      8.780000  100.000000   12.126500   24.000000  711.000000   22.000000   \n",
       "\n",
       "            black       lstat  \n",
       "count  173.000000  173.000000  \n",
       "mean   351.299711   12.917977  \n",
       "std     99.781464    7.293408  \n",
       "min      0.320000    1.920000  \n",
       "25%    371.720000    6.870000  \n",
       "50%    390.070000   12.120000  \n",
       "75%    396.060000   17.210000  \n",
       "max    396.900000   34.370000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BostonTrain.info()\n",
    "BostonTrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1752945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = BostonTrain.iloc[:,1:-1].values\n",
    "Y = BostonTrain.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f33884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7121414b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab2136f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d65ab0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "413c617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a2c85ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prati\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m1,664\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,985</span> (39.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,985\u001b[0m (39.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,985</span> (39.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,985\u001b[0m (39.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=X_train[0].shape))\n",
    "model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dense(1,activation = 'linear'))\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f3b6ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 764.1230 - mae: 17.3726 - val_loss: 27.9974 - val_mae: 4.2755\n",
      "Epoch 2/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.1553 - mae: 5.3028 - val_loss: 79.8810 - val_mae: 7.4923\n",
      "Epoch 3/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 93.2779 - mae: 7.7529 - val_loss: 44.0303 - val_mae: 5.0294\n",
      "Epoch 4/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.2774 - mae: 6.3337 - val_loss: 118.8794 - val_mae: 9.9189\n",
      "Epoch 5/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 93.2477 - mae: 7.9740 - val_loss: 37.2215 - val_mae: 4.7835\n",
      "Epoch 6/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 93.3492 - mae: 7.5945 - val_loss: 44.9310 - val_mae: 5.6694\n",
      "Epoch 7/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43.4779 - mae: 5.1935 - val_loss: 58.1234 - val_mae: 6.7075\n",
      "Epoch 8/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.1615 - mae: 8.8645 - val_loss: 41.2685 - val_mae: 4.9118\n",
      "Epoch 9/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.7394 - mae: 5.8673 - val_loss: 68.7564 - val_mae: 6.9674\n",
      "Epoch 10/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.9143 - mae: 7.1437 - val_loss: 47.7739 - val_mae: 5.5797\n",
      "Epoch 11/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.9939 - mae: 6.0636 - val_loss: 53.7756 - val_mae: 6.3470\n",
      "Epoch 12/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.9196 - mae: 6.8965 - val_loss: 34.7193 - val_mae: 4.2458\n",
      "Epoch 13/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.8862 - mae: 4.6143 - val_loss: 36.1518 - val_mae: 4.8329\n",
      "Epoch 14/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.0999 - mae: 5.5564 - val_loss: 61.0524 - val_mae: 5.4222\n",
      "Epoch 15/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 47.0561 - mae: 5.3068 - val_loss: 33.8011 - val_mae: 4.3491\n",
      "Epoch 16/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.3827 - mae: 5.7809 - val_loss: 62.5172 - val_mae: 6.6374\n",
      "Epoch 17/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.2812 - mae: 6.5354 - val_loss: 33.8459 - val_mae: 4.3136\n",
      "Epoch 18/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.6084 - mae: 4.6330 - val_loss: 24.1997 - val_mae: 3.5670\n",
      "Epoch 19/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42.4617 - mae: 5.0936 - val_loss: 47.9187 - val_mae: 5.5802\n",
      "Epoch 20/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43.3052 - mae: 5.2113 - val_loss: 24.7925 - val_mae: 3.5563\n",
      "Epoch 21/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.4665 - mae: 5.7791 - val_loss: 29.5054 - val_mae: 4.0774\n",
      "Epoch 22/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.4061 - mae: 4.1910 - val_loss: 44.7042 - val_mae: 5.5667\n",
      "Epoch 23/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.5870 - mae: 5.5100 - val_loss: 38.7327 - val_mae: 4.7473\n",
      "Epoch 24/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.2728 - mae: 4.3035 - val_loss: 39.8751 - val_mae: 5.0111\n",
      "Epoch 25/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33.9504 - mae: 4.4354 - val_loss: 39.6410 - val_mae: 4.8515\n",
      "Epoch 26/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.9788 - mae: 6.1163 - val_loss: 26.1188 - val_mae: 3.6392\n",
      "Epoch 27/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.9565 - mae: 5.1155 - val_loss: 27.5483 - val_mae: 3.5768\n",
      "Epoch 28/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 44.7746 - mae: 5.1869 - val_loss: 32.7118 - val_mae: 4.1460\n",
      "Epoch 29/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.4443 - mae: 4.8231 - val_loss: 35.8322 - val_mae: 4.6666\n",
      "Epoch 30/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 54.3243 - mae: 5.8876 - val_loss: 29.0794 - val_mae: 3.8025\n",
      "Epoch 31/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46.4160 - mae: 5.6433 - val_loss: 30.0910 - val_mae: 3.8427\n",
      "Epoch 32/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.3229 - mae: 4.2277 - val_loss: 29.7255 - val_mae: 3.7339\n",
      "Epoch 33/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.4946 - mae: 5.0805 - val_loss: 29.5385 - val_mae: 3.8961\n",
      "Epoch 34/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42.7047 - mae: 5.6689 - val_loss: 29.6075 - val_mae: 4.0459\n",
      "Epoch 35/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48.1733 - mae: 5.2990 - val_loss: 31.8025 - val_mae: 4.1152\n",
      "Epoch 36/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.4673 - mae: 4.0032 - val_loss: 30.8224 - val_mae: 4.1885\n",
      "Epoch 37/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.8525 - mae: 4.4100 - val_loss: 29.5465 - val_mae: 3.9063\n",
      "Epoch 38/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 40.5436 - mae: 4.8241 - val_loss: 25.8241 - val_mae: 3.5369\n",
      "Epoch 39/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33.7292 - mae: 4.3125 - val_loss: 30.5862 - val_mae: 4.1263\n",
      "Epoch 40/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.5342 - mae: 4.1101 - val_loss: 49.3796 - val_mae: 5.6335\n",
      "Epoch 41/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.0153 - mae: 5.4379 - val_loss: 28.0500 - val_mae: 3.9742\n",
      "Epoch 42/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36.2371 - mae: 4.2336 - val_loss: 48.3829 - val_mae: 4.7345\n",
      "Epoch 43/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 49.7453 - mae: 5.3794 - val_loss: 29.4320 - val_mae: 3.7666\n",
      "Epoch 44/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40.8699 - mae: 4.8651 - val_loss: 65.9108 - val_mae: 7.0390\n",
      "Epoch 45/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 49.5174 - mae: 5.3208 - val_loss: 33.2094 - val_mae: 4.5796\n",
      "Epoch 46/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.2973 - mae: 4.0576 - val_loss: 23.8604 - val_mae: 3.3725\n",
      "Epoch 47/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.2998 - mae: 4.0577 - val_loss: 41.9837 - val_mae: 5.1829\n",
      "Epoch 48/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 39.0512 - mae: 4.7288 - val_loss: 25.0085 - val_mae: 3.6106\n",
      "Epoch 49/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.0593 - mae: 4.3662 - val_loss: 23.0692 - val_mae: 3.3313\n",
      "Epoch 50/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5151 - mae: 3.8067 - val_loss: 29.6249 - val_mae: 3.9104\n",
      "Epoch 51/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40.4751 - mae: 4.8758 - val_loss: 28.4149 - val_mae: 3.8109\n",
      "Epoch 52/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 39.0114 - mae: 4.4976 - val_loss: 23.7289 - val_mae: 3.4940\n",
      "Epoch 53/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.8382 - mae: 4.4067 - val_loss: 30.7475 - val_mae: 4.2653\n",
      "Epoch 54/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40.3657 - mae: 5.3026 - val_loss: 26.7591 - val_mae: 3.6470\n",
      "Epoch 55/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45.2902 - mae: 4.6721 - val_loss: 29.8195 - val_mae: 4.0322\n",
      "Epoch 56/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.7857 - mae: 4.3707 - val_loss: 25.8651 - val_mae: 3.8066\n",
      "Epoch 57/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.4873 - mae: 4.5319 - val_loss: 23.8003 - val_mae: 3.4091\n",
      "Epoch 58/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.6234 - mae: 4.2530 - val_loss: 24.6197 - val_mae: 3.4295\n",
      "Epoch 59/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.5130 - mae: 4.3062 - val_loss: 24.9127 - val_mae: 3.5700\n",
      "Epoch 60/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.4533 - mae: 3.7643 - val_loss: 44.2833 - val_mae: 5.5024\n",
      "Epoch 61/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.7985 - mae: 4.1634 - val_loss: 28.0335 - val_mae: 3.8827\n",
      "Epoch 62/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39.0338 - mae: 4.5974 - val_loss: 23.7943 - val_mae: 3.5976\n",
      "Epoch 63/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.1409 - mae: 4.2052 - val_loss: 22.7483 - val_mae: 3.4230\n",
      "Epoch 64/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.8483 - mae: 3.4041 - val_loss: 20.5871 - val_mae: 3.0494\n",
      "Epoch 65/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.0918 - mae: 4.2375 - val_loss: 24.7731 - val_mae: 3.6013\n",
      "Epoch 66/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.1209 - mae: 4.3415 - val_loss: 22.3698 - val_mae: 3.3036\n",
      "Epoch 67/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.5246 - mae: 4.0305 - val_loss: 26.6227 - val_mae: 3.7354\n",
      "Epoch 68/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 27.6788 - mae: 4.0573 - val_loss: 23.8577 - val_mae: 3.4854\n",
      "Epoch 69/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 42.6910 - mae: 4.8836 - val_loss: 23.8718 - val_mae: 3.3581\n",
      "Epoch 70/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.1068 - mae: 3.2550 - val_loss: 24.9222 - val_mae: 3.3969\n",
      "Epoch 71/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.7176 - mae: 3.2977 - val_loss: 27.6332 - val_mae: 3.7849\n",
      "Epoch 72/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42.9584 - mae: 4.5197 - val_loss: 23.0620 - val_mae: 3.3764\n",
      "Epoch 73/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.0863 - mae: 3.6675 - val_loss: 25.3252 - val_mae: 3.4856\n",
      "Epoch 74/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.3029 - mae: 3.9771 - val_loss: 35.7406 - val_mae: 4.3997\n",
      "Epoch 75/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.5201 - mae: 3.7890 - val_loss: 28.3726 - val_mae: 3.6733\n",
      "Epoch 76/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.8688 - mae: 4.1744 - val_loss: 34.6637 - val_mae: 4.3070\n",
      "Epoch 77/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.2501 - mae: 3.8879 - val_loss: 21.9687 - val_mae: 3.2637\n",
      "Epoch 78/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.7767 - mae: 4.4194 - val_loss: 28.2595 - val_mae: 4.0092\n",
      "Epoch 79/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.9297 - mae: 3.6570 - val_loss: 24.3184 - val_mae: 3.4616\n",
      "Epoch 80/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.8939 - mae: 3.2854 - val_loss: 26.9858 - val_mae: 3.6137\n",
      "Epoch 81/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.4717 - mae: 4.1245 - val_loss: 23.7113 - val_mae: 3.4366\n",
      "Epoch 82/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.1327 - mae: 3.8720 - val_loss: 25.3061 - val_mae: 3.5115\n",
      "Epoch 83/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.4830 - mae: 3.4763 - val_loss: 40.5714 - val_mae: 5.1937\n",
      "Epoch 84/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35.5327 - mae: 4.5249 - val_loss: 24.9570 - val_mae: 3.5309\n",
      "Epoch 85/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.2662 - mae: 4.3839 - val_loss: 24.7556 - val_mae: 3.4319\n",
      "Epoch 86/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.6678 - mae: 3.6349 - val_loss: 28.4056 - val_mae: 3.8580\n",
      "Epoch 87/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9405 - mae: 3.5353 - val_loss: 31.4106 - val_mae: 3.9966\n",
      "Epoch 88/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.9108 - mae: 3.8189 - val_loss: 25.6440 - val_mae: 3.6950\n",
      "Epoch 89/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.7553 - mae: 3.5043 - val_loss: 23.6708 - val_mae: 3.4692\n",
      "Epoch 90/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.5876 - mae: 2.9179 - val_loss: 24.0098 - val_mae: 3.2963\n",
      "Epoch 91/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.4938 - mae: 3.6776 - val_loss: 23.3566 - val_mae: 3.5011\n",
      "Epoch 92/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.2745 - mae: 4.1089 - val_loss: 27.3158 - val_mae: 3.8244\n",
      "Epoch 93/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1791 - mae: 3.9727 - val_loss: 26.5570 - val_mae: 3.8492\n",
      "Epoch 94/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 25.7670 - mae: 3.6879 - val_loss: 23.6632 - val_mae: 3.3721\n",
      "Epoch 95/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.0111 - mae: 3.3206 - val_loss: 24.7592 - val_mae: 3.3713\n",
      "Epoch 96/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.0261 - mae: 4.0260 - val_loss: 27.3966 - val_mae: 3.9381\n",
      "Epoch 97/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.3106 - mae: 4.1629 - val_loss: 30.5117 - val_mae: 4.2289\n",
      "Epoch 98/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.2091 - mae: 4.0361 - val_loss: 33.2573 - val_mae: 4.4794\n",
      "Epoch 99/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.5688 - mae: 4.5518 - val_loss: 28.9320 - val_mae: 4.2017\n",
      "Epoch 100/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 26.5164 - mae: 3.7408 - val_loss: 23.9627 - val_mae: 3.4890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19e4b070860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 100, batch_size = 1, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e95c7c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.9850e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "       6.4300e+00, 5.8700e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "       1.8700e+01, 3.9412e+02])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c9dcf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Value:  5.21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Predicted Value:  10.314076\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Value: \", y_test[8])\n",
    "sample = np.array([X_test[8]])\n",
    "print(\"Predicted Value: \", model.predict(sample)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7a0ee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Mean Squared Error (MSE): 23.96266773752288\n",
      "Mean Absolute Error (MAE): 3.4889607456752234\n",
      "R² Score: 0.46949291566788265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_true = y_test.values if hasattr(y_test, 'values') else y_test\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R² Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c706641-52bf-4814-a8a5-84c26982b4ee",
   "metadata": {},
   "source": [
    "🔧 Features (13 total), e.g.:\n",
    "\n",
    "CRIM: crime rate\n",
    "\n",
    "RM: number of rooms\n",
    "\n",
    "AGE: proportion of old homes\n",
    "\n",
    "LSTAT: % lower status population\n",
    "\n",
    "PTRATIO: pupil-teacher ratio\n",
    "\n",
    "TAX: property tax rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e48639-5057-41cd-b921-5ab498f4deea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
